{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "761c239a",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/omkaarwork/Desktop/projects/models-from-scratch/.venv/lib/python3.11/site-packages/tqdm/auto.py:21: TqdmWarning: IProgress not found. Please update jupyter and ipywidgets. See https://ipywidgets.readthedocs.io/en/stable/user_install.html\n",
      "  from .autonotebook import tqdm as notebook_tqdm\n"
     ]
    }
   ],
   "source": [
    "from pathlib import Path\n",
    "import torch\n",
    "import json\n",
    "from transformers import PreTrainedTokenizerFast\n",
    "from safetensors.torch import load_file"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "387e2c27",
   "metadata": {},
   "outputs": [],
   "source": [
    "# run `HF_HUB_ENABLE_HF_TRANSFER=1 uv run hf download LiquidAI/LFM2-1.2B --local-dir /Users/omkaarwork/Desktop/projects/models-from-scratch/liquid-lsm2-1.2b/model`\n",
    "tokenizer_path = \"./model\"\n",
    "tokenizer = PreTrainedTokenizerFast.from_pretrained(tokenizer_path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "f66aa443",
   "metadata": {},
   "outputs": [],
   "source": [
    "with open(\"./model/config.json\", \"r\") as f:\n",
    "    config = json.load(f)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "150b9e0a",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "('<|startoftext|><|endoftext|><|fim_pre|>', 64400, 65536)"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tokenizer.decode([1, 2, 3]), tokenizer.vocab_size, config['vocab_size']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "c610f553",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<All keys matched successfully>"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model = load_file(\"./model/model.safetensors\", device='cpu')\n",
    "embd = torch.nn.Embedding(config['vocab_size'], config['hidden_size'])\n",
    "embd.load_state_dict({'weight': model[f'model.embed_tokens.weight']})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "7e215a38",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'architectures': ['Lfm2ForCausalLM'],\n",
       " 'block_auto_adjust_ff_dim': True,\n",
       " 'block_dim': 2048,\n",
       " 'block_ff_dim': 12288,\n",
       " 'block_ffn_dim_multiplier': 1.0,\n",
       " 'block_mlp_init_scale': 1.0,\n",
       " 'block_multiple_of': 256,\n",
       " 'block_norm_eps': 1e-05,\n",
       " 'block_out_init_scale': 1.0,\n",
       " 'block_use_swiglu': True,\n",
       " 'block_use_xavier_init': True,\n",
       " 'bos_token_id': 1,\n",
       " 'conv_L_cache': 3,\n",
       " 'conv_bias': False,\n",
       " 'conv_dim': 2048,\n",
       " 'conv_dim_out': 2048,\n",
       " 'conv_use_xavier_init': True,\n",
       " 'eos_token_id': 7,\n",
       " 'full_attn_idxs': [2, 5, 8, 10, 12, 14],\n",
       " 'hidden_size': 2048,\n",
       " 'initializer_range': 0.02,\n",
       " 'max_position_embeddings': 128000,\n",
       " 'model_type': 'lfm2',\n",
       " 'norm_eps': 1e-05,\n",
       " 'num_attention_heads': 32,\n",
       " 'num_heads': 32,\n",
       " 'num_hidden_layers': 16,\n",
       " 'num_key_value_heads': 8,\n",
       " 'pad_token_id': 0,\n",
       " 'rope_theta': 1000000.0,\n",
       " 'torch_dtype': 'bfloat16',\n",
       " 'transformers_version': '4.54.0.dev0',\n",
       " 'use_cache': True,\n",
       " 'use_pos_enc': True,\n",
       " 'vocab_size': 65536}"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "config"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "ea7f6597",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['<|startoftext|>', '<|im_start|>', 'system', '\\n', 'Follow', ' the', ' instructions', '.', '<|im_end|>', '\\n', '<|im_start|>', 'user', '\\n', 'Tell', ' us', ' what', ' your', ' name', ' is', '<|im_end|>', '\\n', '<|im_start|>', 'assistant', '\\n']\n"
     ]
    }
   ],
   "source": [
    "messages = [\n",
    "    {\"role\": \"system\", \"content\": 'Follow the instructions.'},\n",
    "    {\"role\": \"user\",   \"content\": \"Tell us what your name is\"}\n",
    "]\n",
    "tokens_i = tokenizer.apply_chat_template(\n",
    "    messages, tokenize=True, add_generation_prompt=True\n",
    ")\n",
    "tokens_i = torch.tensor(tokens_i)\n",
    "prompt_split_as_tokens = [tokenizer.decode([token.item()]) for token in tokens_i]\n",
    "print(prompt_split_as_tokens)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "dfefa47c",
   "metadata": {},
   "outputs": [],
   "source": [
    "def apply_rope(x: torch.Tensor):\n",
    "    _, H, S, D =  x.shape\n",
    "    freqs = 1 / config['rope_theta'] ** (torch.arange(0, D, 2) / D)\n",
    "    freqs_per_token = torch.outer(torch.arange(S), freqs)\n",
    "    freqs_cis = torch.polar(torch.ones_like(freqs_per_token), freqs_per_token)\n",
    "    \n",
    "    x_pairs = x.view(*x.shape[:-1], -1, 2)\n",
    "    x_complex = torch.view_as_complex(x_pairs)\n",
    "    x_rotated = x_complex * freqs_cis\n",
    "    return torch.view_as_real(x_rotated).flatten(-2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "bb407e3f",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['model.embed_tokens.weight',\n",
       " 'model.embedding_norm.weight',\n",
       " 'model.layers.0.conv.conv.weight',\n",
       " 'model.layers.0.conv.in_proj.weight',\n",
       " 'model.layers.0.conv.out_proj.weight',\n",
       " 'model.layers.0.feed_forward.w1.weight',\n",
       " 'model.layers.0.feed_forward.w2.weight',\n",
       " 'model.layers.0.feed_forward.w3.weight',\n",
       " 'model.layers.0.ffn_norm.weight',\n",
       " 'model.layers.0.operator_norm.weight',\n",
       " 'model.layers.1.conv.conv.weight',\n",
       " 'model.layers.1.conv.in_proj.weight',\n",
       " 'model.layers.1.conv.out_proj.weight',\n",
       " 'model.layers.1.feed_forward.w1.weight',\n",
       " 'model.layers.1.feed_forward.w2.weight',\n",
       " 'model.layers.1.feed_forward.w3.weight',\n",
       " 'model.layers.1.ffn_norm.weight',\n",
       " 'model.layers.1.operator_norm.weight',\n",
       " 'model.layers.10.feed_forward.w1.weight',\n",
       " 'model.layers.10.feed_forward.w2.weight']"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "list(model.keys())[:20]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "3c0c8a2c",
   "metadata": {},
   "outputs": [],
   "source": [
    "tokens = tokens_i.clone()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "ab9f0eef",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "My \"name\" is AI Assistant. I don't have a physical form or a name like humans do. I'm here to help you with any questions or tasks you'd like assistance with.<|im_end|>"
     ]
    }
   ],
   "source": [
    "while tokens[-1].item() != tokenizer.eos_token_id:\n",
    "\n",
    "    x = embd(tokens).unsqueeze(0)\n",
    "\n",
    "    for layer in range(config['num_hidden_layers']):\n",
    "        S = x.shape[1]\n",
    "\n",
    "        x_norm = torch.nn.functional.rms_norm(x, normalized_shape=(config['hidden_size'],), weight=model[f'model.layers.{layer}.operator_norm.weight'], eps=config['norm_eps']).type(torch.bfloat16)\n",
    "\n",
    "        if layer in config['full_attn_idxs']:  # Attention\n",
    "            xq = x_norm @ model[f'model.layers.{layer}.self_attn.q_proj.weight'].T\n",
    "            xk = x_norm @ model[f'model.layers.{layer}.self_attn.k_proj.weight'].T\n",
    "            xv = x_norm @ model[f'model.layers.{layer}.self_attn.v_proj.weight'].T\n",
    "\n",
    "            xq = xq.view(1, S, config['num_attention_heads'], -1).transpose(-2, -3)\n",
    "            xk = xk.view(1, S, config['num_key_value_heads'], -1).repeat_interleave(config['num_attention_heads'] // config['num_key_value_heads'], dim=2).transpose(-2, -3)\n",
    "            xv = xv.view(1, S, config['num_key_value_heads'], -1).repeat_interleave(config['num_attention_heads'] // config['num_key_value_heads'], dim=2).transpose(-2, -3)\n",
    "\n",
    "            xq = apply_rope(xq.type(torch.float32))\n",
    "            xk = apply_rope(xk.type(torch.float32))\n",
    "\n",
    "            xq = torch.nn.functional.rms_norm(xq, normalized_shape=(xq.shape[-1],), weight=model[f'model.layers.{layer}.self_attn.q_layernorm.weight'], eps=config['norm_eps'])\n",
    "            xk = torch.nn.functional.rms_norm(xk, normalized_shape=(xk.shape[-1],), weight=model[f'model.layers.{layer}.self_attn.k_layernorm.weight'], eps=config['norm_eps'])\n",
    "            \n",
    "            score = ((xq @ xk.transpose(-1, -2)) / (xk.shape[-1] ** 0.5)).type(torch.float32) + torch.triu(torch.full((S, S), float('-inf')), diagonal=1)\n",
    "            attn = torch.softmax(score, dim=-1) @ xv.float()\n",
    "            x_operator = attn.to(torch.bfloat16).transpose(1, 2).reshape(1, S, -1) @ model[f'model.layers.{layer}.self_attn.out_proj.weight'].T\n",
    "        else: # Conv layer\n",
    "            # (1, S, D) @ (1, D, 3D) = (1, S, 3D) -> T -> (1, 3D, S)\n",
    "            BCx = (x_norm @ model[f'model.layers.{layer}.conv.in_proj.weight'].T).transpose(-1, -2)\n",
    "\n",
    "            # (1, 3D, S) -> (1, D, S), (1, D, S), (1, D, S)\n",
    "            B, C, x_c = BCx.chunk(3, dim=-2)\n",
    "\n",
    "            # (1, D, S) * (1, D, S) -> (1, D, S)\n",
    "            x_c = B * x_c\n",
    "\n",
    "            # (1, D, S) conv (D, 1, 3) -> (1, D, S + 2)\n",
    "            x_c = torch.nn.functional.conv1d(\n",
    "                x_c,\n",
    "                weight=model[f'model.layers.{layer}.conv.conv.weight'],\n",
    "                padding=config['conv_L_cache'] - 1,\n",
    "                groups=config['hidden_size'],\n",
    "            )\n",
    "\n",
    "            # (1, D, S) * (1, D, S) -> (1, D, S)\n",
    "            x_c = C * x_c[:, :, :S]\n",
    "\n",
    "            # (1, S, D) @ (D, D) -> (1, S, D)\n",
    "            x_operator = x_c.transpose(-1, -2) @ model[f'model.layers.{layer}.conv.out_proj.weight'].T\n",
    "\n",
    "        x = x + x_operator\n",
    "\n",
    "        x_norm = torch.nn.functional.rms_norm(x, normalized_shape=(config['hidden_size'],), weight=model[f'model.layers.{layer}.ffn_norm.weight'], eps=config['norm_eps']).type(torch.bfloat16)\n",
    "\n",
    "        ffn_w1 = model[f\"model.layers.{layer}.feed_forward.w1.weight\"].type(torch.bfloat16)\n",
    "        ffn_w2 = model[f\"model.layers.{layer}.feed_forward.w2.weight\"].type(torch.bfloat16)\n",
    "        ffn_w3 = model[f\"model.layers.{layer}.feed_forward.w3.weight\"].type(torch.bfloat16)\n",
    "        ffn_o = (torch.nn.functional.silu(x_norm @ torch.transpose(ffn_w1, 0, 1)) * (x_norm @ torch.transpose(ffn_w3, 0, 1))) @ torch.transpose(ffn_w2, 0, 1)\n",
    "\n",
    "        x = x + ffn_o\n",
    "\n",
    "    x = torch.nn.functional.rms_norm(x, normalized_shape=(config['hidden_size'],), weight=model['model.embedding_norm.weight'], eps=config['norm_eps']).type(torch.bfloat16)\n",
    "    out = x @ model[f'model.embed_tokens.weight'].T\n",
    "\n",
    "    out_softmax = torch.nn.functional.softmax(out[:, -1, :].float(), dim=-1)\n",
    "    values, indices = torch.topk(out_softmax, k=1)\n",
    "    tokens = torch.cat((tokens, torch.tensor([indices])), dim=-1)\n",
    "    print(tokenizer.decode(indices[0]), end='', flush=True)\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "llama3-py (3.11.0)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
