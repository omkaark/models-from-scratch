{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "2236c191",
   "metadata": {},
   "outputs": [],
   "source": [
    "from pathlib import Path\n",
    "import tiktoken\n",
    "from tiktoken.load import load_tiktoken_bpe\n",
    "import torch\n",
    "import json"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "f9175c37",
   "metadata": {},
   "outputs": [],
   "source": [
    "tokenizer_path = \"../model/tokenizer.model\"\n",
    "special_tokens = [\n",
    "            \"<|begin_of_text|>\",\n",
    "            \"<|end_of_text|>\",\n",
    "            \"<|reserved_special_token_0|>\",\n",
    "            \"<|reserved_special_token_1|>\",\n",
    "            \"<|reserved_special_token_2|>\",\n",
    "            \"<|reserved_special_token_3|>\",\n",
    "            \"<|start_header_id|>\",\n",
    "            \"<|end_header_id|>\",\n",
    "            \"<|reserved_special_token_4|>\",\n",
    "            \"<|eot_id|>\",  # end of turn\n",
    "        ] + [f\"<|reserved_special_token_{i}|>\" for i in range(5, 256 - 5)]\n",
    "mergeable_ranks = load_tiktoken_bpe(tokenizer_path)\n",
    "tokenizer = tiktoken.Encoding(\n",
    "    name=Path(tokenizer_path).name,\n",
    "    pat_str=r\"(?i:'s|'t|'re|'ve|'m|'ll|'d)|[^\\r\\n\\p{L}\\p{N}]?\\p{L}+|\\p{N}{1,3}| ?[^\\s\\p{L}\\p{N}]+[\\r\\n]*|\\s*[\\r\\n]+|\\s+(?!\\S)|\\s+\",\n",
    "    mergeable_ranks=mergeable_ranks,\n",
    "    special_tokens={token: len(mergeable_ranks) + i for i, token in enumerate(special_tokens)},\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "b6b7462d",
   "metadata": {},
   "outputs": [],
   "source": [
    "with open(\"../model/params.json\", \"r\") as f:\n",
    "    config = json.load(f)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "709717e5",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<All keys matched successfully>"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model = torch.load(\"../model/consolidated.00.pth\", map_location=torch.device('cpu'))\n",
    "embd = torch.nn.Embedding(tokenizer.n_vocab, config['dim'])\n",
    "embd.load_state_dict({'weight': model['tok_embeddings.weight']})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "1e3c7241",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['<|begin_of_text|>', 'the', ' answer', ' to', ' the', ' ultimate', ' question', ' of', ' life', ',', ' the', ' universe', ',', ' and', ' everything', ' is', ' ']\n"
     ]
    }
   ],
   "source": [
    "prompt = \"the answer to the ultimate question of life, the universe, and everything is \"\n",
    "tokens_i = [128000] + tokenizer.encode(prompt)\n",
    "tokens_i = torch.tensor(tokens_i)\n",
    "prompt_split_as_tokens = [tokenizer.decode([token.item()]) for token in tokens_i]\n",
    "print(prompt_split_as_tokens)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "d71a6ad9",
   "metadata": {},
   "outputs": [],
   "source": [
    "SEQ_LEN = 1024\n",
    "EMBD_DIM = 512\n",
    "tokens = tokens_i.clone()\n",
    "x = embd(tokens)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d3b96832",
   "metadata": {},
   "outputs": [],
   "source": [
    "def apply_rope(x, start_pos=0):\n",
    "    \"\"\"Apply rotary positional encoding to queries or keys\"\"\"\n",
    "    seq_len, head_dim = x.shape[-2], x.shape[-1]\n",
    "    print('pre-rope x shape:', x.shape)\n",
    "\n",
    "    # create base frequencies\n",
    "    freqs = 1.0 / (config['rope_theta'] ** (torch.arange(0, head_dim, 2).float() / head_dim))\n",
    "    print('freqs shape:', freqs.shape)\n",
    "    \n",
    "    # create frequency for each position\n",
    "    freqs_for_each_token = torch.outer(torch.arange(start_pos, start_pos + seq_len), freqs)\n",
    "    print('freqs_for_each_token shape:', freqs_for_each_token.shape)\n",
    "\n",
    "    freqs_cis = torch.polar(torch.ones_like(freqs_for_each_token), freqs_for_each_token)\n",
    "    print('freqs_cis shape:', freqs_cis.shape)\n",
    "    \n",
    "    # apply rotation\n",
    "    x_split = x.float().view(*x.shape[:-1], -1, 2)\n",
    "    print('x_split shape:', x_split.shape)\n",
    "\n",
    "    x_complex = torch.view_as_complex(x_split)\n",
    "    print('x_complex shape:', x_complex.shape)\n",
    "\n",
    "    x_rotated = x_complex * freqs_cis\n",
    "    print('x_rotated shape:', x_rotated.shape)\n",
    "\n",
    "    out = torch.view_as_real(x_rotated).flatten(-2).type_as(x)\n",
    "    print('out shape:', out.shape)\n",
    "\n",
    "    return out"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9eab0a42",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.19216537475585938 ms\n"
     ]
    }
   ],
   "source": [
    "with torch.no_grad():\n",
    "    x = embd(tokens)\n",
    "    seq_len = x.shape[0]\n",
    "    head_dim = config['dim'] // config['n_heads']\n",
    "\n",
    "    for layer in range(1):\n",
    "        # RMS 1\n",
    "        rms_1 = torch.nn.functional.rms_norm(x, normalized_shape=(x.shape[-1],), weight=model[f\"layers.{layer}.attention_norm.weight\"], eps=config[\"norm_eps\"])\n",
    "\n",
    "        xq = rms_1 @ torch.transpose(model[f\"layers.{layer}.attention.wq.weight\"].type(torch.float32), 0, 1)\n",
    "        xq = xq.view(seq_len, config['n_heads'], head_dim).transpose(0, 1).contiguous()\n",
    "\n",
    "        xq = apply_rope(xq)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b976a77c",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "llama3-py (3.11.0)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
